# service.py (Versi√≥n Profesional y Robusta)
import bentoml
from bentoml.io import JSON, Text
import logging

from predict_model import load_model, predict

# --- MEJORA: Configuraci√≥n de Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
log = logging.getLogger('bentoml.service')

log.info("üöÄ Inicializando el servicio de clasificaci√≥n de intenciones...")
model_info = load_model()

if not model_info:
    log.error("‚ùå INICIO FALLIDO: No se pudo cargar el modelo. El servicio no podr√° funcionar.")
    # En un sistema real, esto podr√≠a alertar a un sistema de monitoreo.
    raise RuntimeError("Error cr√≠tico: No se pudo cargar el modelo.")

log.info("‚úÖ Modelo cargado y listo para recibir peticiones.")

@bentoml.service
class IntentClassifier:

    @bentoml.api(input=Text(), output=JSON())
    def classify(self, input_text: str, ctx: bentoml.Context) -> dict:
        log.info(f"Petici√≥n recibida para clasificar: '{input_text}'")
        
        # --- MEJORA: Validaci√≥n de Entrada ---
        if not input_text or not input_text.strip():
            log.warning("Petici√≥n rechazada: el texto de entrada est√° vac√≠o.")
            # Se establece el c√≥digo de estado HTTP a 400 Bad Request
            ctx.response.status_code = 400
            return {"error": "El texto de entrada no puede estar vac√≠o."}

        try:
            # --- MEJORA: Manejo de Errores a nivel de API ---
            predictions = predict(input_text, model_info)
            
            if not predictions:
                log.error("La predicci√≥n devolvi√≥ un resultado vac√≠o, revisa los logs del modelo.")
                ctx.response.status_code = 500
                return {"error": "Ocurri√≥ un error interno durante la predicci√≥n."}

            log.info(f"Predicciones generadas exitosamente.")
            return {"predictions": predictions}

        except Exception as e:
            log.exception("Excepci√≥n no controlada en el endpoint /classify")
            ctx.response.status_code = 500
            return {"error": "Ocurri√≥ un error interno inesperado."}

    # --- MEJORA: Punto de Verificaci√≥n de Salud (Health Check) ---
    @bentoml.api(route="/health", input=Text(), output=JSON())
    def health(self, _: str, ctx: bentoml.Context) -> dict:
        """
        Endpoint simple para verificar que el servicio est√° vivo y funcionando.
        """
        log.info("Health check recibido.")
        return {"status": "ok"}